{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from function import fun1,fun2\n",
    "from my_NN import Mynetwork\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 确保 model 文件夹存在\n",
    "os.makedirs('./model_parameter', exist_ok=True)\n",
    "\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_t_per_interval_and_generate_f_start(dtype,device,seg_step=16,batch_size=32,f_start_min=0.1,f_start_max=0.9):\n",
    "    t_seg=torch.linspace(0,1,seg_step+1,dtype=dtype,device=device)\n",
    "    t_seg=t_seg.repeat(batch_size,1)\n",
    "    \n",
    "    '''no random move'''\n",
    "    # rand_move=torch.empty((batch_size,seg_step+1),dtype=dtype,device=device).uniform_(-0.5/seg_step,0.5/seg_step)\n",
    "    # rand_move[:,0]=0\n",
    "    # rand_move[:,-1]=0\n",
    "    \n",
    "    # t_seg+=rand_move\n",
    "\n",
    "    \n",
    "    f_start_rand=torch.empty((batch_size,1),dtype=dtype,device=device).uniform_(f_start_min,f_start_max)\n",
    "    \n",
    "    return t_seg , f_start_rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11])\n"
     ]
    }
   ],
   "source": [
    "#function test\n",
    "k,k_f=sample_t_per_interval_and_generate_f_start(torch.float32,torch.device('cuda'),seg_step=10,batch_size=32)\n",
    "print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consist_loss_calculator(model,t_seg,f_start_rand,seg_step,loss_func,batch_size,boundary_func=fun1,depth=3,f_start_min=0.01,f_start_max=0.99):\n",
    "    #注意这里t_seg还是size为(batch_size,seg_step+1)的tensor\n",
    "    t_seg_copy=t_seg.clone()\n",
    "    dtype=t_seg.dtype\n",
    "    device=t_seg.device\n",
    "    consist_loss=0\n",
    "    for i in range(depth):\n",
    "        \n",
    "        mid_point=(t_seg_copy[:,1:]+t_seg_copy[:,:-1])/2\n",
    "        #这里构建下一个深度的t_seg_copy\n",
    "        temp_result=torch.empty((batch_size,t_seg_copy.shape[1]*2-1),dtype=t_seg.dtype,device=t_seg.device)\n",
    "        #不知道torch.empty的多次使用会不会导致内存消耗过大?\n",
    "        temp_result[:,::2]=t_seg_copy\n",
    "        temp_result[:,1::2]=mid_point\n",
    "        \n",
    "        #这里利用 mid_point 和 t_seg_copy 计算这一层的consist_loss\n",
    "        #至于f的初值为什么可以取随机数，还没想太明白\n",
    "        \n",
    "        delta=t_seg_copy[:,1:]-t_seg_copy[:,:-1]\n",
    "        \n",
    "        delta=delta.unsqueeze(-1)\n",
    "        #unsqueeze并不改变delta的维度，所以需要进行赋值，而delta.unsqueeze_(-1)可以直接改变delta的维度\n",
    "        \n",
    "        f_rand_n=torch.empty(delta.shape,dtype=dtype,device=device).uniform_(f_start_min,f_start_max)\n",
    "        \n",
    "        one_step_result=f_rand_n+model.forward(f_rand_n,t_seg_copy[:,:-1].unsqueeze(-1),delta)\n",
    "        \n",
    "        two_step_result=f_rand_n+model.forward(f_rand_n,t_seg_copy[:,:-1].unsqueeze(-1),delta/2)\n",
    "        two_step_result=two_step_result+model.forward(two_step_result,mid_point.unsqueeze(-1),delta/2)\n",
    "        \n",
    "        #归一化方案，这里的归一化方案是对每个batch的consist_loss进行归一化，而不是对整个batch的consist_loss进行归一化，采用了lixiang的归一化方案\n",
    "        norm_factors = torch.sum(delta, dim=0)**2\n",
    "        \n",
    "        consist_loss+=loss_func(one_step_result/norm_factors,two_step_result/norm_factors)\n",
    "        \n",
    "        t_seg_copy=temp_result\n",
    "    return consist_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_loss_calculator(model,t_seg,f_start_rand,seg_step,loss_func,batch_size,boundary_func=fun1,f_start_min=0.1,f_start_max=0.9):\n",
    "    #注意这里t_seg还是size为(batch_size,seg_step+1)的tensor\n",
    "    t_seg_copy=t_seg.clone()\n",
    "    t_seg_copy=t_seg_copy.unsqueeze_(-1)\n",
    "    delta=t_seg_copy[:,1:]-t_seg_copy[:,:-1]\n",
    "    \n",
    "    func_f_end_value=boundary_func(f_start_rand)\n",
    "    \n",
    "    model_f_end_value=f_start_rand\n",
    "    for i in range(seg_step):\n",
    "        model_f_end_value+=model.forward(model_f_end_value,t_seg_copy[:,i],delta[:,i])\n",
    "    \n",
    "    \n",
    "    boundary_loss=loss_func(model_f_end_value,func_f_end_value)\n",
    "    #是否需要做归一化？\n",
    "    \n",
    "    return boundary_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,loss_func,batch_size,seg_step,dtype,device,boundary_func=fun1,f_start_min=0.1,f_start_max=0.9,consist_depth=3):\n",
    "    t_seg,f_start_rand=sample_t_per_interval_and_generate_f_start(dtype=dtype,device=device,seg_step=seg_step,batch_size=batch_size,f_start_min=f_start_min,f_start_max=f_start_max)\n",
    "    \n",
    "    boundary_loss=boundary_loss_calculator(model,t_seg,f_start_rand,seg_step,loss_func,batch_size,boundary_func=boundary_func,f_start_min=f_start_min,f_start_max=f_start_max)\n",
    "    consist_loss=consist_loss_calculator(model,t_seg,f_start_rand,seg_step,loss_func,batch_size,boundary_func=boundary_func,f_start_min=f_start_min,f_start_max=f_start_max,depth=consist_depth)/(seg_step*(2**consist_depth))\n",
    "    if debug:\n",
    "        print('boundary_loss:',boundary_loss)\n",
    "        print('consist_loss:',consist_loss)\n",
    "    loss=boundary_loss+consist_loss\n",
    "    loss=boundary_loss\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(model,optimizer,loss_func,device,dtype,batch_size,consist_depth=3,boundary_func=fun1):\n",
    "    #train_loop\n",
    "    optimizer.zero_grad()\n",
    "    #计算loss\n",
    "    loss=get_loss(model,loss_func,batch_size,seg_step=2,dtype=dtype,device=device,boundary_func=boundary_func,consist_depth=consist_depth,f_start_min=0.1,f_start_max=0.9)\n",
    "    #反向传播\n",
    "    loss.backward()\n",
    "    #更新参数\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,device='cuda',dtype=torch.float32,\n",
    "          epoch=100,batch_size=32,lr=0.01,consist_depth=3,\n",
    "          use_lr_scheduler=False,boundary_func=fun1):\n",
    "    loss_list = []\n",
    "    \n",
    "    loss_func = nn.MSELoss()\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 **({\"fused\": True} if \"cuda\" in str(device) else {}))#这里的fused=True，是为了使用apex加速\n",
    "\n",
    "    # Use ReduceLROnPlateau as the learning rate scheduler\n",
    "    if use_lr_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                               patience=20,\n",
    "                                                               threshold=1e-4,\n",
    "                                                               cooldown=6)\n",
    "    \n",
    "    init_time = time.time()\n",
    "    for i in range(epoch):\n",
    "        loss_term=iteration(model,optimizer,loss_func,device,dtype,batch_size,consist_depth=consist_depth,boundary_func=boundary_func)\n",
    "        #设计中，iteration中已经完成反向传播，所以这里不需要再进行反向传播\n",
    "        loss_list.append(loss_term)\n",
    "        if (i+1)%20==0:\n",
    "            print(f'epoch:{i+1},loss:{loss_term},time:{time.time()-init_time},lr:{optimizer.param_groups[0][\"lr\"]}')\n",
    "        if (i+1)%50==0:\n",
    "            torch.save(model.state_dict(),f'./model_parameter/model_para_batch{batch_size}_epoch{epoch}_consist_depth{consist_depth}.pth')\n",
    "        if use_lr_scheduler:\n",
    "            scheduler.step(loss_term)\n",
    "        if optimizer.param_groups[0][\"lr\"] <= 1.1e-8:\n",
    "            break\n",
    "    print('terminal epoch: ',i+1)\n",
    "    \n",
    "    if debug==False:\n",
    "        plt.plot(loss_list,label='loss')\n",
    "        plt.legend()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习率调整机制以后再加进来 \n",
    "    #lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) if use_lr_scheduler else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now using cuda !\n",
      "epoch:20,loss:3.074772834777832,time:0.541541576385498,lr:0.001\n",
      "epoch:40,loss:2.7587294578552246,time:1.071315050125122,lr:0.001\n",
      "epoch:60,loss:2.5681610107421875,time:1.6022696495056152,lr:0.001\n",
      "epoch:80,loss:2.192605972290039,time:2.075927257537842,lr:0.001\n",
      "epoch:100,loss:2.368701219558716,time:2.541663408279419,lr:0.001\n",
      "epoch:120,loss:1.6126699447631836,time:3.0085322856903076,lr:0.001\n",
      "epoch:140,loss:1.5603280067443848,time:3.4741313457489014,lr:0.001\n",
      "epoch:160,loss:1.6354180574417114,time:3.9402148723602295,lr:0.001\n",
      "epoch:180,loss:1.3877018690109253,time:4.405429363250732,lr:0.001\n",
      "epoch:200,loss:1.4483425617218018,time:4.871241569519043,lr:0.001\n",
      "epoch:220,loss:1.4089916944503784,time:5.338366508483887,lr:0.001\n",
      "epoch:240,loss:1.0136439800262451,time:5.805170774459839,lr:0.001\n",
      "epoch:260,loss:1.0370731353759766,time:6.27215576171875,lr:0.001\n",
      "epoch:280,loss:0.9785276055335999,time:6.738963603973389,lr:0.001\n",
      "epoch:300,loss:0.8918449878692627,time:7.205020427703857,lr:0.001\n",
      "epoch:320,loss:0.8063247203826904,time:7.672066926956177,lr:0.001\n",
      "epoch:340,loss:0.7079952955245972,time:8.138254165649414,lr:0.001\n",
      "epoch:360,loss:0.7099161744117737,time:8.604919910430908,lr:0.001\n",
      "epoch:380,loss:0.6152905225753784,time:9.070280075073242,lr:0.001\n",
      "epoch:400,loss:0.42470884323120117,time:9.536574125289917,lr:0.001\n",
      "epoch:420,loss:0.4403589069843292,time:10.0032057762146,lr:0.001\n",
      "epoch:440,loss:0.3184330463409424,time:10.469128131866455,lr:0.001\n",
      "epoch:460,loss:0.3406370282173157,time:10.935882329940796,lr:0.001\n",
      "epoch:480,loss:0.34412306547164917,time:11.401995658874512,lr:0.001\n",
      "epoch:500,loss:0.3282364308834076,time:11.867969751358032,lr:0.001\n",
      "epoch:520,loss:0.3094186782836914,time:12.334112167358398,lr:0.001\n",
      "epoch:540,loss:0.24609345197677612,time:12.80182433128357,lr:0.001\n",
      "epoch:560,loss:0.28129372000694275,time:13.330418586730957,lr:0.001\n",
      "epoch:580,loss:0.21768346428871155,time:13.825554132461548,lr:0.001\n",
      "epoch:600,loss:0.1993604302406311,time:14.292993068695068,lr:0.001\n",
      "epoch:620,loss:0.2096250057220459,time:14.760360479354858,lr:0.001\n",
      "epoch:640,loss:0.2344760000705719,time:15.227088689804077,lr:0.001\n",
      "epoch:660,loss:0.18303164839744568,time:15.695226192474365,lr:0.001\n",
      "epoch:680,loss:0.13244286179542542,time:16.1623637676239,lr:0.001\n",
      "epoch:700,loss:0.1329251527786255,time:16.62950825691223,lr:0.001\n",
      "epoch:720,loss:0.16348712146282196,time:17.096906900405884,lr:0.001\n",
      "epoch:740,loss:0.13897636532783508,time:17.564990282058716,lr:0.001\n",
      "epoch:760,loss:0.10538031160831451,time:18.03268074989319,lr:0.001\n",
      "epoch:780,loss:0.15270349383354187,time:18.49984121322632,lr:0.001\n",
      "epoch:800,loss:0.16207236051559448,time:18.966962575912476,lr:0.001\n",
      "epoch:820,loss:0.10905840992927551,time:19.43460249900818,lr:0.001\n",
      "epoch:840,loss:0.08021122962236404,time:19.90229058265686,lr:0.001\n",
      "epoch:860,loss:0.12569600343704224,time:20.369600772857666,lr:0.001\n",
      "epoch:880,loss:0.11081783473491669,time:20.842891454696655,lr:0.001\n",
      "epoch:900,loss:0.10168600082397461,time:21.369812726974487,lr:0.001\n",
      "epoch:920,loss:0.07865495979785919,time:21.850329875946045,lr:0.001\n",
      "epoch:940,loss:0.06406658887863159,time:22.316076040267944,lr:0.001\n",
      "epoch:960,loss:0.07657177001237869,time:22.782190084457397,lr:0.001\n",
      "epoch:980,loss:0.07894580066204071,time:23.248169898986816,lr:0.001\n",
      "epoch:1000,loss:0.058520786464214325,time:23.713189840316772,lr:0.001\n",
      "epoch:1020,loss:0.09482555836439133,time:24.1788809299469,lr:0.001\n",
      "epoch:1040,loss:0.051850512623786926,time:24.644132614135742,lr:0.001\n",
      "epoch:1060,loss:0.05097941309213638,time:25.109484434127808,lr:0.001\n",
      "epoch:1080,loss:0.050193723291158676,time:25.575220346450806,lr:0.001\n",
      "epoch:1100,loss:0.04617644473910332,time:26.04021143913269,lr:0.001\n",
      "epoch:1120,loss:0.044264376163482666,time:26.506147861480713,lr:0.001\n",
      "epoch:1140,loss:0.039679110050201416,time:26.972159147262573,lr:0.001\n",
      "epoch:1160,loss:0.055685222148895264,time:27.43851613998413,lr:0.001\n",
      "epoch:1180,loss:0.048078835010528564,time:27.904494524002075,lr:0.001\n",
      "epoch:1200,loss:0.03924420103430748,time:28.36955189704895,lr:0.001\n",
      "epoch:1220,loss:0.03688559681177139,time:28.8354275226593,lr:0.001\n",
      "epoch:1240,loss:0.029728354886174202,time:29.300599575042725,lr:0.001\n",
      "epoch:1260,loss:0.03459051251411438,time:29.766836643218994,lr:0.001\n",
      "epoch:1280,loss:0.029672283679246902,time:30.24396777153015,lr:0.001\n",
      "epoch:1300,loss:0.02185005694627762,time:30.773890256881714,lr:0.001\n",
      "epoch:1320,loss:0.030020885169506073,time:31.24907684326172,lr:0.001\n",
      "epoch:1340,loss:0.028425617143511772,time:31.716931581497192,lr:0.001\n",
      "epoch:1360,loss:0.023555058985948563,time:32.18458533287048,lr:0.001\n",
      "epoch:1380,loss:0.02849283255636692,time:32.65135979652405,lr:0.001\n",
      "epoch:1400,loss:0.028107453137636185,time:33.11774945259094,lr:0.001\n",
      "epoch:1420,loss:0.02483265846967697,time:33.58430290222168,lr:0.001\n",
      "epoch:1440,loss:0.016215680167078972,time:34.05135416984558,lr:0.001\n",
      "epoch:1460,loss:0.01886073127388954,time:34.518683195114136,lr:0.001\n",
      "epoch:1480,loss:0.021689530462026596,time:34.985822677612305,lr:0.001\n",
      "epoch:1500,loss:0.02118038199841976,time:35.45228385925293,lr:0.001\n",
      "epoch:1520,loss:0.028100281953811646,time:35.919798612594604,lr:0.001\n",
      "epoch:1540,loss:0.018269499763846397,time:36.386526584625244,lr:0.001\n",
      "epoch:1560,loss:0.024684254080057144,time:36.85504102706909,lr:0.001\n",
      "epoch:1580,loss:0.0168424341827631,time:37.32222533226013,lr:0.001\n",
      "epoch:1600,loss:0.019483858719468117,time:37.7897207736969,lr:0.001\n",
      "epoch:1620,loss:0.015720224007964134,time:38.25713586807251,lr:0.001\n",
      "epoch:1640,loss:0.013498453423380852,time:38.72384428977966,lr:0.001\n",
      "epoch:1660,loss:0.013286197558045387,time:39.19094276428223,lr:0.001\n",
      "epoch:1680,loss:0.024710746482014656,time:39.65823245048523,lr:0.001\n",
      "epoch:1700,loss:0.011427813209593296,time:40.12472987174988,lr:0.001\n",
      "epoch:1720,loss:0.014762348495423794,time:40.5915265083313,lr:0.001\n",
      "epoch:1740,loss:0.01286276150494814,time:41.05819249153137,lr:0.001\n",
      "epoch:1760,loss:0.012612195685505867,time:41.52528262138367,lr:0.001\n",
      "epoch:1780,loss:0.011380786076188087,time:41.99253058433533,lr:0.001\n",
      "epoch:1800,loss:0.007685196120291948,time:42.46039962768555,lr:0.001\n",
      "epoch:1820,loss:0.013844968751072884,time:42.92772102355957,lr:0.001\n",
      "epoch:1840,loss:0.009419519454240799,time:43.39426064491272,lr:0.001\n",
      "epoch:1860,loss:0.01314281951636076,time:43.86244177818298,lr:0.001\n",
      "epoch:1880,loss:0.007763965986669064,time:44.329445362091064,lr:0.001\n",
      "epoch:1900,loss:0.013514744117856026,time:44.79639720916748,lr:0.001\n",
      "epoch:1920,loss:0.00837110634893179,time:45.31535506248474,lr:0.001\n",
      "epoch:1940,loss:0.012196017429232597,time:45.84414839744568,lr:0.001\n",
      "epoch:1960,loss:0.008274704217910767,time:46.37364864349365,lr:0.001\n",
      "epoch:1980,loss:0.008612025529146194,time:46.90277361869812,lr:0.001\n",
      "epoch:2000,loss:0.00544077530503273,time:47.431602478027344,lr:0.001\n",
      "epoch:2020,loss:0.007297980599105358,time:47.94638657569885,lr:0.001\n",
      "epoch:2040,loss:0.006549288984388113,time:48.412370443344116,lr:0.001\n",
      "epoch:2060,loss:0.007489036303013563,time:48.878134965896606,lr:0.001\n",
      "epoch:2080,loss:0.012104138731956482,time:49.34320855140686,lr:0.001\n",
      "epoch:2100,loss:0.009989079087972641,time:49.80851745605469,lr:0.001\n",
      "epoch:2120,loss:0.011670779436826706,time:50.27352023124695,lr:0.001\n",
      "epoch:2140,loss:0.007261098362505436,time:50.73854064941406,lr:0.001\n",
      "epoch:2160,loss:0.0076339589431881905,time:51.20453667640686,lr:0.001\n",
      "epoch:2180,loss:0.004787658341228962,time:51.6700234413147,lr:0.001\n",
      "epoch:2200,loss:0.00707186758518219,time:52.135966062545776,lr:0.001\n",
      "epoch:2220,loss:0.00471949577331543,time:52.601805448532104,lr:0.001\n",
      "epoch:2240,loss:0.007077346555888653,time:53.066967725753784,lr:0.001\n",
      "epoch:2260,loss:0.008523297496140003,time:53.53258728981018,lr:0.001\n",
      "epoch:2280,loss:0.0041983770206570625,time:53.9983913898468,lr:0.001\n",
      "epoch:2300,loss:0.004459153860807419,time:54.463308572769165,lr:0.001\n",
      "epoch:2320,loss:0.007036404684185982,time:54.92941927909851,lr:0.001\n",
      "epoch:2340,loss:0.00473384652286768,time:55.395670652389526,lr:0.001\n",
      "epoch:2360,loss:0.004805203527212143,time:55.86113142967224,lr:0.001\n",
      "epoch:2380,loss:0.0033467370085418224,time:56.326823472976685,lr:0.001\n",
      "epoch:2400,loss:0.004915487952530384,time:56.79268455505371,lr:0.001\n",
      "epoch:2420,loss:0.004020577296614647,time:57.25853991508484,lr:0.001\n",
      "epoch:2440,loss:0.0059847841039299965,time:57.724106550216675,lr:0.001\n",
      "epoch:2460,loss:0.005966879427433014,time:58.19015049934387,lr:0.001\n",
      "epoch:2480,loss:0.0049817836843431,time:58.65566420555115,lr:0.001\n",
      "epoch:2500,loss:0.0052668023854494095,time:59.12067532539368,lr:0.001\n",
      "epoch:2520,loss:0.005622704513370991,time:59.58686900138855,lr:0.001\n",
      "epoch:2540,loss:0.0038061579689383507,time:60.05178093910217,lr:0.001\n",
      "epoch:2560,loss:0.0028026876971125603,time:60.517287254333496,lr:0.001\n",
      "epoch:2580,loss:0.005509377457201481,time:60.98297667503357,lr:0.001\n",
      "epoch:2600,loss:0.0031197145581245422,time:61.447778940200806,lr:0.001\n",
      "epoch:2620,loss:0.006125008221715689,time:61.93650698661804,lr:0.001\n",
      "epoch:2640,loss:0.004743822384625673,time:62.46590065956116,lr:0.001\n",
      "epoch:2660,loss:0.0038709347136318684,time:62.93537616729736,lr:0.001\n",
      "epoch:2680,loss:0.0037015248090028763,time:63.40236711502075,lr:0.001\n",
      "epoch:2700,loss:0.003975793719291687,time:63.86961650848389,lr:0.001\n",
      "epoch:2720,loss:0.0036332199815660715,time:64.33634495735168,lr:0.001\n",
      "epoch:2740,loss:0.002993034664541483,time:64.8036961555481,lr:0.001\n",
      "epoch:2760,loss:0.0033880306873470545,time:65.27093815803528,lr:0.001\n",
      "epoch:2780,loss:0.003932126332074404,time:65.73773884773254,lr:0.001\n",
      "epoch:2800,loss:0.002764832926914096,time:66.20436668395996,lr:0.001\n",
      "epoch:2820,loss:0.0031235781498253345,time:66.67134070396423,lr:0.001\n",
      "epoch:2840,loss:0.0026409835554659367,time:67.13820171356201,lr:0.001\n",
      "epoch:2860,loss:0.0031440516468137503,time:67.61428356170654,lr:0.001\n",
      "epoch:2880,loss:0.0029822001233696938,time:68.08119177818298,lr:0.001\n",
      "epoch:2900,loss:0.003242600243538618,time:68.55060601234436,lr:0.001\n",
      "epoch:2920,loss:0.002999918069690466,time:69.01773238182068,lr:0.001\n",
      "epoch:2940,loss:0.0027915965765714645,time:69.48510885238647,lr:0.001\n",
      "epoch:2960,loss:0.005029676482081413,time:69.95274066925049,lr:0.001\n",
      "epoch:2980,loss:0.004350185394287109,time:70.41939806938171,lr:0.001\n",
      "epoch:3000,loss:0.005501440726220608,time:70.88607954978943,lr:0.001\n",
      "epoch:3020,loss:0.003470627125352621,time:71.35318040847778,lr:0.001\n",
      "epoch:3040,loss:0.0025264720898121595,time:71.82000136375427,lr:0.001\n",
      "epoch:3060,loss:0.002814312931150198,time:72.28720498085022,lr:0.001\n",
      "epoch:3080,loss:0.0018449154449626803,time:72.75414228439331,lr:0.001\n",
      "epoch:3100,loss:0.0022796213161200285,time:73.22105813026428,lr:0.001\n",
      "epoch:3120,loss:0.002547669690102339,time:73.68845725059509,lr:0.001\n",
      "epoch:3140,loss:0.0025480904150754213,time:74.15538573265076,lr:0.001\n",
      "epoch:3160,loss:0.001799601363018155,time:74.6227810382843,lr:0.001\n",
      "epoch:3180,loss:0.0024873875081539154,time:75.08998560905457,lr:0.001\n",
      "epoch:3200,loss:0.002249715384095907,time:75.55739831924438,lr:0.001\n",
      "epoch:3220,loss:0.003136271145194769,time:76.02514100074768,lr:0.001\n",
      "epoch:3240,loss:0.002635228680446744,time:76.49300050735474,lr:0.001\n",
      "epoch:3260,loss:0.001984455157071352,time:76.96084880828857,lr:0.001\n",
      "epoch:3280,loss:0.0018357173539698124,time:77.4606146812439,lr:0.001\n",
      "epoch:3300,loss:0.0031821175944060087,time:77.98971199989319,lr:0.001\n",
      "epoch:3320,loss:0.0026825510431081057,time:78.51942420005798,lr:0.001\n",
      "epoch:3340,loss:0.0017699794843792915,time:79.04851984977722,lr:0.001\n",
      "epoch:3360,loss:0.00194453913718462,time:79.57807779312134,lr:0.001\n",
      "epoch:3380,loss:0.0019567422568798065,time:80.10682511329651,lr:0.001\n",
      "epoch:3400,loss:0.0015581963816657662,time:80.5761251449585,lr:0.001\n",
      "epoch:3420,loss:0.002457468304783106,time:81.04207634925842,lr:0.001\n",
      "epoch:3440,loss:0.0018341615796089172,time:81.50709509849548,lr:0.001\n",
      "epoch:3460,loss:0.001828500535339117,time:81.97251486778259,lr:0.001\n",
      "epoch:3480,loss:0.0020619183778762817,time:82.43740320205688,lr:0.001\n",
      "epoch:3500,loss:0.002195891225710511,time:82.90260744094849,lr:0.001\n",
      "epoch:3520,loss:0.0015699011273682117,time:83.36817336082458,lr:0.001\n",
      "epoch:3540,loss:0.0017656063428148627,time:83.8335690498352,lr:0.001\n",
      "epoch:3560,loss:0.001775220618583262,time:84.29896926879883,lr:0.001\n",
      "epoch:3580,loss:0.001382751390337944,time:84.7652485370636,lr:0.001\n",
      "epoch:3600,loss:0.0020150351338088512,time:85.23063564300537,lr:0.001\n",
      "epoch:3620,loss:0.0020778244361281395,time:85.6960380077362,lr:0.001\n",
      "epoch:3640,loss:0.0012693163007497787,time:86.16114711761475,lr:0.001\n",
      "epoch:3660,loss:0.0019980468787252903,time:86.63877129554749,lr:0.001\n",
      "epoch:3680,loss:0.0016375143313780427,time:87.16805481910706,lr:0.001\n",
      "epoch:3700,loss:0.0019896947778761387,time:87.63801717758179,lr:0.001\n",
      "epoch:3720,loss:0.0014507672749459743,time:88.10434055328369,lr:0.001\n",
      "epoch:3740,loss:0.0011684377677738667,time:88.57102394104004,lr:0.001\n",
      "epoch:3760,loss:0.0018962231697514653,time:89.03780436515808,lr:0.001\n",
      "epoch:3780,loss:0.0013120572548359632,time:89.50410890579224,lr:0.001\n",
      "epoch:3800,loss:0.0012360410764813423,time:89.97033452987671,lr:0.001\n",
      "epoch:3820,loss:0.001669862773269415,time:90.43754267692566,lr:0.001\n",
      "epoch:3840,loss:0.0008836983470246196,time:90.90395450592041,lr:0.001\n",
      "epoch:3860,loss:0.0014881384558975697,time:91.3703362941742,lr:0.001\n",
      "epoch:3880,loss:0.0014804479433223605,time:91.83666944503784,lr:0.001\n",
      "epoch:3900,loss:0.0009524507913738489,time:92.30151081085205,lr:0.001\n",
      "epoch:3920,loss:0.0016696627717465162,time:92.767822265625,lr:0.001\n",
      "epoch:3940,loss:0.0015790089964866638,time:93.23363161087036,lr:0.001\n",
      "epoch:3960,loss:0.0014406726695597172,time:93.70039582252502,lr:0.001\n",
      "epoch:3980,loss:0.0016751247458159924,time:94.1666054725647,lr:0.001\n",
      "epoch:4000,loss:0.0009115910506807268,time:94.63291764259338,lr:0.001\n",
      "epoch:4020,loss:0.0018451513024047017,time:95.09942531585693,lr:0.001\n",
      "epoch:4040,loss:0.0012954261619597673,time:95.56608772277832,lr:0.001\n",
      "epoch:4060,loss:0.0012551579857245088,time:96.03246355056763,lr:0.001\n",
      "epoch:4080,loss:0.001668964745476842,time:96.49895644187927,lr:0.001\n",
      "epoch:4100,loss:0.0014641250018030405,time:96.96495389938354,lr:0.001\n",
      "epoch:4120,loss:0.0009967468213289976,time:97.43161273002625,lr:0.001\n",
      "epoch:4140,loss:0.0012412918731570244,time:97.8975441455841,lr:0.001\n",
      "epoch:4160,loss:0.0012840605340898037,time:98.36471891403198,lr:0.001\n",
      "epoch:4180,loss:0.001018413808196783,time:98.8310534954071,lr:0.001\n",
      "epoch:4200,loss:0.0008771454449743032,time:99.29702734947205,lr:0.001\n",
      "epoch:4220,loss:0.0010707402834668756,time:99.76380944252014,lr:0.001\n",
      "epoch:4240,loss:0.0014427679125219584,time:100.23027014732361,lr:0.001\n",
      "epoch:4260,loss:0.0007625247235409915,time:100.69695973396301,lr:0.001\n",
      "epoch:4280,loss:0.0023049800656735897,time:101.1629376411438,lr:0.001\n",
      "epoch:4300,loss:0.0009332462213933468,time:101.62936067581177,lr:0.001\n",
      "epoch:4320,loss:0.0010541595984250307,time:102.09696936607361,lr:0.001\n",
      "epoch:4340,loss:0.0013645458966493607,time:102.56381559371948,lr:0.001\n",
      "epoch:4360,loss:0.0014076792867854238,time:103.03069019317627,lr:0.001\n",
      "epoch:4380,loss:0.001757230143994093,time:103.49692034721375,lr:0.001\n",
      "epoch:4400,loss:0.0012517878785729408,time:103.9630389213562,lr:0.001\n",
      "epoch:4420,loss:0.0010069831041619182,time:104.42959403991699,lr:0.001\n",
      "epoch:4440,loss:0.0008755757007747889,time:104.89601826667786,lr:0.001\n",
      "epoch:4460,loss:0.0007730426732450724,time:105.36400961875916,lr:0.001\n",
      "epoch:4480,loss:0.0009256654302589595,time:105.83080387115479,lr:0.001\n",
      "epoch:4500,loss:0.0012274871114641428,time:106.29695796966553,lr:0.001\n",
      "epoch:4520,loss:0.0015088224317878485,time:106.7641007900238,lr:0.001\n",
      "epoch:4540,loss:0.0011418613139539957,time:107.23029804229736,lr:0.001\n",
      "epoch:4560,loss:0.0007782576722092927,time:107.73891282081604,lr:0.001\n",
      "epoch:4580,loss:0.0007798841688781977,time:108.20685315132141,lr:0.001\n",
      "epoch:4600,loss:0.001126313116401434,time:108.6732439994812,lr:0.001\n",
      "epoch:4620,loss:0.001394265447743237,time:109.1398663520813,lr:0.001\n",
      "epoch:4640,loss:0.0011083352146670222,time:109.60594940185547,lr:0.001\n",
      "epoch:4660,loss:0.0013325258623808622,time:110.07288551330566,lr:0.001\n",
      "epoch:4680,loss:0.0008797819027677178,time:110.53907251358032,lr:0.001\n",
      "epoch:4700,loss:0.0009525362984277308,time:111.0051519870758,lr:0.001\n",
      "epoch:4720,loss:0.0009484323090873659,time:111.47185134887695,lr:0.001\n",
      "epoch:4740,loss:0.001236604992300272,time:111.93831586837769,lr:0.001\n",
      "epoch:4760,loss:0.001120150787755847,time:112.40537357330322,lr:0.001\n",
      "epoch:4780,loss:0.001304836361669004,time:112.87170886993408,lr:0.001\n",
      "epoch:4800,loss:0.0007977572386153042,time:113.3371069431305,lr:0.001\n",
      "epoch:4820,loss:0.0008705974905751646,time:113.80333375930786,lr:0.001\n",
      "epoch:4840,loss:0.0012613278813660145,time:114.27000379562378,lr:0.001\n",
      "epoch:4860,loss:0.000702574965544045,time:114.73622035980225,lr:0.001\n",
      "epoch:4880,loss:0.0009388014441356063,time:115.20309400558472,lr:0.001\n",
      "epoch:4900,loss:0.0007997269276529551,time:115.66961455345154,lr:0.001\n",
      "epoch:4920,loss:0.0010913581354543567,time:116.13626456260681,lr:0.001\n",
      "epoch:4940,loss:0.0008398772333748639,time:116.6025550365448,lr:0.001\n",
      "epoch:4960,loss:0.0007238154066726565,time:117.06942462921143,lr:0.001\n",
      "epoch:4980,loss:0.0009976716246455908,time:117.5354483127594,lr:0.001\n",
      "epoch:5000,loss:0.0009761186083778739,time:118.00149178504944,lr:0.001\n",
      "epoch:5020,loss:0.0007528453134000301,time:118.4684145450592,lr:0.001\n",
      "epoch:5040,loss:0.0006143404170870781,time:118.9347312450409,lr:0.001\n",
      "epoch:5060,loss:0.0007674894877709448,time:119.40105080604553,lr:0.001\n",
      "epoch:5080,loss:0.0007289719069376588,time:119.86720371246338,lr:0.001\n",
      "epoch:5100,loss:0.000841895816847682,time:120.33366250991821,lr:0.001\n",
      "epoch:5120,loss:0.0008430826710537076,time:120.80020046234131,lr:0.001\n",
      "epoch:5140,loss:0.0006834731320850551,time:121.26633191108704,lr:0.001\n",
      "epoch:5160,loss:0.0006130392430350184,time:121.7336356639862,lr:0.001\n",
      "epoch:5180,loss:0.000962014717515558,time:122.2002182006836,lr:0.001\n",
      "epoch:5200,loss:0.0008605971815995872,time:122.66632962226868,lr:0.001\n",
      "epoch:5220,loss:0.0008720026235096157,time:123.13286995887756,lr:0.001\n",
      "epoch:5240,loss:0.0008151876972988248,time:123.59896755218506,lr:0.001\n",
      "epoch:5260,loss:0.0008085910812951624,time:124.06568717956543,lr:0.001\n",
      "epoch:5280,loss:0.0008775614551268518,time:124.53207015991211,lr:0.001\n",
      "epoch:5300,loss:0.0006695638294331729,time:124.99796462059021,lr:0.001\n",
      "epoch:5320,loss:0.0007387359510175884,time:125.46476101875305,lr:0.001\n",
      "epoch:5340,loss:0.0008448346052318811,time:125.93116068840027,lr:0.001\n",
      "epoch:5360,loss:0.0008651951211504638,time:126.39817190170288,lr:0.001\n",
      "epoch:5380,loss:0.0012724907137453556,time:126.86425733566284,lr:0.001\n",
      "epoch:5400,loss:0.0006994117866270244,time:127.33085918426514,lr:0.001\n",
      "epoch:5420,loss:0.0006077185971662402,time:127.79721713066101,lr:0.001\n",
      "epoch:5440,loss:0.0006296135834418237,time:128.26318192481995,lr:0.001\n",
      "epoch:5460,loss:0.0009174523293040693,time:128.73030018806458,lr:0.001\n",
      "epoch:5480,loss:0.0009934637928381562,time:129.1966850757599,lr:0.001\n",
      "epoch:5500,loss:0.0007046118844300508,time:129.6628921031952,lr:0.001\n",
      "epoch:5520,loss:0.0010214389767497778,time:130.12935280799866,lr:0.001\n",
      "epoch:5540,loss:0.0006698176730424166,time:130.59572863578796,lr:0.001\n",
      "epoch:5560,loss:0.0008252629195339978,time:131.0623161792755,lr:0.001\n",
      "epoch:5580,loss:0.0009930550586432219,time:131.5288577079773,lr:0.001\n",
      "epoch:5600,loss:0.000779062625952065,time:131.99502325057983,lr:0.001\n",
      "epoch:5620,loss:0.0006540407193824649,time:132.46164631843567,lr:0.001\n",
      "epoch:5640,loss:0.0007962480885908008,time:132.92768549919128,lr:0.001\n",
      "epoch:5660,loss:0.0008727154927328229,time:133.3949213027954,lr:0.001\n",
      "epoch:5680,loss:0.0005494417855516076,time:133.86179542541504,lr:0.001\n",
      "epoch:5700,loss:0.0009151037083938718,time:134.32850646972656,lr:0.001\n",
      "epoch:5720,loss:0.0007478374755010009,time:134.7951261997223,lr:0.001\n",
      "epoch:5740,loss:0.0010052346624433994,time:135.2615225315094,lr:0.001\n",
      "epoch:5760,loss:0.0008893220801837742,time:135.72840213775635,lr:0.001\n",
      "epoch:5780,loss:0.0006070340168662369,time:136.1947844028473,lr:0.001\n",
      "epoch:5800,loss:0.0006265637348406017,time:136.66157698631287,lr:0.001\n",
      "epoch:5820,loss:0.0007914546877145767,time:137.12807440757751,lr:0.001\n",
      "epoch:5840,loss:0.0005109113408252597,time:137.59446120262146,lr:0.001\n",
      "epoch:5860,loss:0.0013871080009266734,time:138.06094121932983,lr:0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m consist_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#training part \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconsist_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsist_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_lr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mboundary_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogram ended here \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m terminal time: \u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39minitial_time)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave model parameter in file name : model_para_batch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_consist_depth\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconsist_depth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 21\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, device, dtype, epoch, batch_size, lr, consist_depth, use_lr_scheduler, boundary_func)\u001b[0m\n\u001b[1;32m     19\u001b[0m init_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m---> 21\u001b[0m     loss_term\u001b[38;5;241m=\u001b[39m\u001b[43miteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconsist_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsist_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mboundary_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboundary_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#设计中，iteration中已经完成反向传播，所以这里不需要再进行反向传播\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     loss_list\u001b[38;5;241m.\u001b[39mappend(loss_term)\n",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m, in \u001b[0;36miteration\u001b[0;34m(model, optimizer, loss_func, device, dtype, batch_size, consist_depth, boundary_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#更新参数\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    initial_time=time.time()\n",
    "    if torch.cuda.is_available():\n",
    "        device='cuda'\n",
    "        print('now using cuda !')\n",
    "    else:\n",
    "        device='cpu'\n",
    "        print('now using cpu !')\n",
    "    dtype=torch.float32\n",
    "    model=Mynetwork().to(device=device,dtype=dtype)\n",
    "    \n",
    "    \n",
    "    batch_size=512\n",
    "    epoch=10000\n",
    "    if debug:epoch=1\n",
    "    consist_depth=12\n",
    "    #training part \n",
    "    training(model,device,dtype,epoch=epoch,lr=0.001,batch_size=batch_size,consist_depth=consist_depth,use_lr_scheduler=False,boundary_func=fun1)\n",
    "    \n",
    "    print('program ended here \\n terminal time: ', time.time()-initial_time)\n",
    "    print(f'save model parameter in file name : model_para_batch{batch_size}_epoch{epoch}_consist_depth{consist_depth}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
