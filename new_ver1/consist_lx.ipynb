{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.006824912270531058, LR = 0.01\n",
      "Epoch 10: Loss = 0.0010035329542006366, LR = 0.01\n",
      "Epoch 15: Loss = 0.000503842813486699, LR = 0.01\n",
      "Epoch 20: Loss = 0.0003889272084052209, LR = 0.01\n",
      "Epoch 25: Loss = 0.00031811183362151496, LR = 0.01\n",
      "Epoch 30: Loss = 0.00026873248134506866, LR = 0.01\n",
      "Epoch 35: Loss = 0.00022834799165138975, LR = 0.01\n",
      "Epoch 40: Loss = 0.00019791071463259868, LR = 0.01\n",
      "Epoch 45: Loss = 0.00017969494365388528, LR = 0.01\n",
      "Epoch 50: Loss = 0.00015908253772067837, LR = 0.01\n",
      "Epoch 55: Loss = 0.0001451222888135817, LR = 0.01\n",
      "Epoch 60: Loss = 0.00013085765203868505, LR = 0.01\n",
      "Epoch 65: Loss = 0.00011825650199170923, LR = 0.01\n",
      "Epoch 70: Loss = 0.00013861243132851087, LR = 0.01\n",
      "Epoch 75: Loss = 9.702369061415084e-05, LR = 0.01\n",
      "Epoch 80: Loss = 0.00015593564148730366, LR = 0.01\n",
      "Epoch 85: Loss = 0.0001114422320824815, LR = 0.01\n",
      "Epoch 90: Loss = 0.00011103393262601458, LR = 0.01\n",
      "Epoch 95: Loss = 0.00015209556477202568, LR = 0.01\n",
      "Epoch 100: Loss = 0.00020046263398398878, LR = 0.01\n",
      "Epoch 105: Loss = 0.00011173375696671428, LR = 0.01\n",
      "Epoch 110: Loss = 6.457682684413157e-05, LR = 0.01\n",
      "Epoch 115: Loss = 0.00015913351671770215, LR = 0.01\n",
      "Epoch 120: Loss = 5.890407192055136e-05, LR = 0.01\n",
      "Epoch 125: Loss = 0.0005986297874187585, LR = 0.01\n",
      "Epoch 130: Loss = 6.178829517011764e-05, LR = 0.01\n",
      "Epoch 135: Loss = 0.00010814156848937273, LR = 0.01\n",
      "Epoch 140: Loss = 8.029328228076338e-05, LR = 0.01\n",
      "Epoch 145: Loss = 5.0702460612228606e-05, LR = 0.01\n",
      "Epoch 150: Loss = 0.00011521775013534352, LR = 0.01\n",
      "Epoch 155: Loss = 0.00024274767383758444, LR = 0.01\n",
      "Epoch 160: Loss = 0.00013581920848082518, LR = 0.01\n",
      "Epoch 165: Loss = 8.671467821841361e-05, LR = 0.01\n",
      "Epoch 170: Loss = 3.883386534653255e-05, LR = 0.001\n",
      "Epoch 175: Loss = 3.774948800128186e-05, LR = 0.001\n",
      "Epoch 180: Loss = 3.752805423573591e-05, LR = 0.001\n",
      "Epoch 185: Loss = 3.721858411154244e-05, LR = 0.001\n",
      "Epoch 190: Loss = 3.6728429222421255e-05, LR = 0.001\n",
      "Epoch 195: Loss = 3.6482029372564284e-05, LR = 0.001\n",
      "Epoch 200: Loss = 3.6195386201143265e-05, LR = 0.001\n",
      "Epoch 205: Loss = 3.593802648538258e-05, LR = 0.001\n",
      "Epoch 210: Loss = 3.534770894475514e-05, LR = 0.001\n",
      "Epoch 215: Loss = 3.4596698242239654e-05, LR = 0.001\n",
      "Epoch 220: Loss = 3.343309526826488e-05, LR = 0.001\n",
      "Epoch 225: Loss = 3.2453066978632705e-05, LR = 0.001\n",
      "Epoch 230: Loss = 3.0265299528764444e-05, LR = 0.001\n",
      "Epoch 235: Loss = 2.9834974384357338e-05, LR = 0.001\n",
      "Epoch 240: Loss = 2.9347392228373792e-05, LR = 0.001\n",
      "Epoch 245: Loss = 2.8861088594567263e-05, LR = 0.001\n",
      "Epoch 250: Loss = 2.8619438808163977e-05, LR = 0.001\n",
      "Epoch 255: Loss = 2.8164634613858652e-05, LR = 0.001\n",
      "Epoch 260: Loss = 2.806268253152666e-05, LR = 0.001\n",
      "Epoch 265: Loss = 2.7629495889414102e-05, LR = 0.001\n",
      "Epoch 270: Loss = 2.7380754772821092e-05, LR = 0.001\n",
      "Epoch 275: Loss = 2.7161471734871157e-05, LR = 0.001\n",
      "Epoch 280: Loss = 2.673555104593106e-05, LR = 0.001\n",
      "Epoch 285: Loss = 2.697240392990352e-05, LR = 0.001\n",
      "Epoch 290: Loss = 2.6648576749721542e-05, LR = 0.001\n",
      "Epoch 295: Loss = 2.6643683668226004e-05, LR = 0.001\n",
      "Epoch 300: Loss = 2.6101068669959204e-05, LR = 0.001\n",
      "Epoch 305: Loss = 2.5877749976643827e-05, LR = 0.001\n",
      "Epoch 310: Loss = 2.591953648334311e-05, LR = 0.001\n",
      "Epoch 315: Loss = 2.5492906615909305e-05, LR = 0.001\n",
      "Epoch 320: Loss = 2.5645356117820484e-05, LR = 0.001\n",
      "Epoch 325: Loss = 2.5336780254292535e-05, LR = 0.001\n",
      "Epoch 330: Loss = 2.5312173647762393e-05, LR = 0.001\n",
      "Epoch 335: Loss = 2.500052119103202e-05, LR = 0.001\n",
      "Epoch 340: Loss = 2.5001033918670146e-05, LR = 0.001\n",
      "Epoch 345: Loss = 2.498375806680997e-05, LR = 0.001\n",
      "Epoch 350: Loss = 2.473930567248317e-05, LR = 0.001\n",
      "Epoch 355: Loss = 2.452935723340488e-05, LR = 0.001\n",
      "Epoch 360: Loss = 2.464536009938456e-05, LR = 0.001\n",
      "Epoch 365: Loss = 2.439725881231425e-05, LR = 0.001\n",
      "Epoch 370: Loss = 2.4134386194418767e-05, LR = 0.001\n",
      "Epoch 375: Loss = 2.413589095340285e-05, LR = 0.001\n",
      "Epoch 380: Loss = 2.3857323640186223e-05, LR = 0.001\n",
      "Epoch 385: Loss = 2.3885906557552516e-05, LR = 0.001\n",
      "Epoch 390: Loss = 2.384182948844682e-05, LR = 0.001\n",
      "Epoch 395: Loss = 2.366372655160376e-05, LR = 0.001\n",
      "Epoch 400: Loss = 2.3798950905984384e-05, LR = 0.001\n",
      "Epoch 405: Loss = 2.348839529986435e-05, LR = 0.001\n",
      "Epoch 410: Loss = 2.322270529475645e-05, LR = 0.001\n",
      "Epoch 415: Loss = 2.329352355445735e-05, LR = 0.001\n",
      "Epoch 420: Loss = 2.313643426532508e-05, LR = 0.001\n",
      "Epoch 425: Loss = 2.3276411411643494e-05, LR = 0.001\n",
      "Epoch 430: Loss = 2.285665300405526e-05, LR = 0.001\n",
      "Epoch 435: Loss = 2.3069228745953296e-05, LR = 0.001\n",
      "Epoch 440: Loss = 2.271883568027988e-05, LR = 0.001\n",
      "Epoch 445: Loss = 2.2801181103204726e-05, LR = 0.001\n",
      "Epoch 450: Loss = 2.259019470329804e-05, LR = 0.001\n",
      "Epoch 455: Loss = 2.254393416478706e-05, LR = 0.001\n",
      "Epoch 460: Loss = 2.2713332782586804e-05, LR = 0.001\n",
      "Epoch 465: Loss = 2.2353376834871597e-05, LR = 0.001\n",
      "Epoch 470: Loss = 2.20944727971073e-05, LR = 0.001\n",
      "Epoch 475: Loss = 2.2090195216151187e-05, LR = 0.001\n",
      "Epoch 480: Loss = 2.186643882851058e-05, LR = 0.001\n",
      "Epoch 485: Loss = 2.1888732590014115e-05, LR = 0.001\n",
      "Epoch 490: Loss = 2.18159959786135e-05, LR = 0.001\n",
      "Epoch 495: Loss = 2.1770775447294e-05, LR = 0.001\n",
      "Epoch 500: Loss = 2.1997445855959086e-05, LR = 0.001\n",
      "Epoch 505: Loss = 2.1643081254296703e-05, LR = 0.001\n",
      "Epoch 510: Loss = 2.1520417931242264e-05, LR = 0.001\n",
      "Epoch 515: Loss = 2.1581029614026193e-05, LR = 0.001\n",
      "Epoch 520: Loss = 2.1358224330469966e-05, LR = 0.001\n",
      "Epoch 525: Loss = 2.0983487729608896e-05, LR = 0.001\n",
      "Epoch 530: Loss = 2.0830907033086987e-05, LR = 0.001\n",
      "Epoch 535: Loss = 2.061085160676157e-05, LR = 0.001\n",
      "Epoch 540: Loss = 2.0567746105371043e-05, LR = 0.001\n",
      "Epoch 545: Loss = 2.0513817617029417e-05, LR = 0.001\n",
      "Epoch 550: Loss = 2.0142356106589432e-05, LR = 0.001\n",
      "Epoch 555: Loss = 2.0216496068314882e-05, LR = 0.001\n",
      "Epoch 560: Loss = 2.0070514665349037e-05, LR = 0.001\n",
      "Epoch 565: Loss = 2.0656812466768315e-05, LR = 0.001\n",
      "Epoch 570: Loss = 2.0010830667160917e-05, LR = 0.001\n",
      "Epoch 575: Loss = 2.003279564632976e-05, LR = 0.001\n",
      "Epoch 580: Loss = 1.9904885448340792e-05, LR = 0.001\n",
      "Epoch 585: Loss = 1.9800988638962735e-05, LR = 0.001\n",
      "Epoch 590: Loss = 1.948947465280071e-05, LR = 0.001\n",
      "Epoch 595: Loss = 2.037048739111924e-05, LR = 0.001\n",
      "Epoch 600: Loss = 2.0556748950184556e-05, LR = 0.001\n",
      "Epoch 605: Loss = 1.946397378560505e-05, LR = 0.001\n",
      "Epoch 610: Loss = 1.9532450551196234e-05, LR = 0.001\n",
      "Epoch 615: Loss = 1.98998234282044e-05, LR = 0.001\n",
      "Epoch 620: Loss = 1.900309166558145e-05, LR = 0.001\n",
      "Epoch 625: Loss = 1.8885712279370637e-05, LR = 0.001\n",
      "Epoch 630: Loss = 1.8899391989180003e-05, LR = 0.001\n",
      "Epoch 635: Loss = 1.969504842236347e-05, LR = 0.001\n",
      "Epoch 640: Loss = 2.0088141809537774e-05, LR = 0.001\n",
      "Epoch 645: Loss = 1.9107818843622226e-05, LR = 0.001\n",
      "Epoch 650: Loss = 1.9061154262089985e-05, LR = 0.001\n",
      "Epoch 655: Loss = 1.9106608533547842e-05, LR = 0.001\n",
      "Epoch 660: Loss = 1.876234227893292e-05, LR = 0.001\n",
      "Epoch 665: Loss = 1.954707681761647e-05, LR = 0.001\n",
      "Epoch 670: Loss = 1.9664580804601428e-05, LR = 0.001\n",
      "Epoch 675: Loss = 1.8846068314815057e-05, LR = 0.001\n",
      "Epoch 680: Loss = 1.8165985920859384e-05, LR = 0.001\n",
      "Epoch 685: Loss = 1.7924383200806915e-05, LR = 0.001\n",
      "Epoch 690: Loss = 1.822130502660002e-05, LR = 0.001\n",
      "Epoch 695: Loss = 1.845328642957611e-05, LR = 0.001\n",
      "Epoch 700: Loss = 1.694841466814978e-05, LR = 0.0001\n",
      "Epoch 705: Loss = 1.687907547420764e-05, LR = 0.0001\n",
      "Epoch 710: Loss = 1.7041423006958212e-05, LR = 0.0001\n",
      "Epoch 715: Loss = 1.6989670712064253e-05, LR = 0.0001\n",
      "Epoch 720: Loss = 1.668413779043476e-05, LR = 0.0001\n",
      "Epoch 725: Loss = 1.6776089523773408e-05, LR = 0.0001\n",
      "Epoch 730: Loss = 1.671304175943078e-05, LR = 0.0001\n",
      "Epoch 735: Loss = 1.695124183243024e-05, LR = 0.0001\n",
      "Epoch 740: Loss = 1.6730891502447776e-05, LR = 0.0001\n",
      "Epoch 745: Loss = 1.668377012720157e-05, LR = 0.0001\n",
      "Epoch 750: Loss = 1.6878602536962717e-05, LR = 0.0001\n",
      "Epoch 755: Loss = 1.6622196199023165e-05, LR = 0.0001\n",
      "Epoch 760: Loss = 1.7042415720425197e-05, LR = 0.0001\n",
      "Epoch 765: Loss = 1.6856455886227195e-05, LR = 0.0001\n",
      "Epoch 770: Loss = 1.6665537486915127e-05, LR = 0.0001\n",
      "Epoch 775: Loss = 1.6848262021085247e-05, LR = 1e-05\n",
      "Epoch 780: Loss = 1.678177773101197e-05, LR = 1e-05\n",
      "Epoch 785: Loss = 1.666297612246126e-05, LR = 1e-05\n",
      "Epoch 790: Loss = 1.6774827599874698e-05, LR = 1e-05\n",
      "Epoch 795: Loss = 1.6813771026136237e-05, LR = 1e-05\n",
      "Epoch 800: Loss = 1.6656770412737387e-05, LR = 1e-05\n",
      "Epoch 805: Loss = 1.6713708646420855e-05, LR = 1e-05\n",
      "Epoch 810: Loss = 1.639759898353077e-05, LR = 1.0000000000000002e-06\n",
      "Epoch 815: Loss = 1.6597372450632975e-05, LR = 1.0000000000000002e-06\n",
      "Epoch 820: Loss = 1.6694144733264693e-05, LR = 1.0000000000000002e-06\n",
      "Epoch 825: Loss = 1.6517024050699547e-05, LR = 1.0000000000000002e-06\n",
      "Epoch 830: Loss = 1.6548329540455597e-05, LR = 1.0000000000000002e-06\n",
      "Epoch 835: Loss = 1.688470388216956e-05, LR = 1.0000000000000002e-07\n",
      "Epoch 840: Loss = 1.6659834273013985e-05, LR = 1.0000000000000002e-07\n",
      "Epoch 845: Loss = 1.66705895026098e-05, LR = 1.0000000000000002e-07\n",
      "Epoch 850: Loss = 1.6573909306316637e-05, LR = 1.0000000000000002e-07\n",
      "terminal epoch:  853\n",
      "list_of_loss_mean_epoch:  [np.float64(0.3607332184910774), np.float64(0.0003666265693027526), np.float64(0.00019515235726430546), np.float64(0.00013054305418336298), np.float64(0.0001215636302731582), np.float64(0.0003984987924923189), np.float64(5.843245889991522e-05), np.float64(6.409305569832213e-05), np.float64(0.0003466092148300959), np.float64(3.7141767279536e-05), np.float64(3.579083067961619e-05), np.float64(3.3350794637954095e-05), np.float64(2.9033301188974292e-05), np.float64(2.7750230628953432e-05), np.float64(2.6858919682126725e-05), np.float64(2.6353240627940977e-05), np.float64(2.5713132117743953e-05), np.float64(2.5166971454382292e-05), np.float64(2.4852006163200713e-05), np.float64(2.4205503450502874e-05), np.float64(2.3780786023053224e-05), np.float64(2.3076470370142488e-05), np.float64(2.2736478513252223e-05), np.float64(2.2536410824613995e-05), np.float64(2.2114136754680658e-05), np.float64(2.1687917524104705e-05), np.float64(2.1767244334114366e-05), np.float64(2.0316088921390474e-05), np.float64(2.0419644215508015e-05), np.float64(2.0241694301148527e-05), np.float64(2.0258940594430896e-05), np.float64(1.9177160311301122e-05), np.float64(2.0816768483200576e-05), np.float64(2.5959590857382864e-05), np.float64(1.7711292457534e-05), np.float64(1.6905624534047092e-05), np.float64(1.7008682789310114e-05), np.float64(1.6868354123289464e-05), np.float64(1.671453674134682e-05), np.float64(1.6603503809164977e-05), np.float64(1.672340613367851e-05), np.float64(1.6679535974617465e-05), np.float64(1.6655536683174432e-05)]\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "Run time showed here :    1017.3171279430389\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from function import *\n",
    "from my_NN import *\n",
    "import ycx_para_config as ycx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "debug=False\n",
    "debug_2=False\n",
    "\n",
    "boundary_loss_list=[]\n",
    "consist_loss_list=[]\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Get the absolute path to the 'network' directory\n",
    "network_path = os.path.join(notebook_dir, '../network')\n",
    "\n",
    "# Add the 'network' directory to sys.path\n",
    "sys.path.append(os.path.abspath(network_path))\n",
    "\n",
    "\n",
    "def equally_random_points_in_interval(n, num_samples=1):\n",
    "    # Define the equal division points (excluding 0 and 1)\n",
    "    nodes = np.linspace(1/n, 1-1/n, n-1)\n",
    "\n",
    "    # Define the segment length, which is 1/n\n",
    "    segment_length = 1/n\n",
    "\n",
    "    # Define sigma as segment_length / 3\n",
    "    sigma = segment_length / 5\n",
    "\n",
    "    # Sample randomly around each node using normal distribution\n",
    "    #sampled_points = np.array([np.random.normal(loc=node, scale=sigma, size=num_samples) for node in nodes])\n",
    "    sampled_points = np.array([np.random.rand()*2*ycx.random_amplititude/n+node-ycx.random_amplititude/n for node in nodes])\n",
    "    \n",
    "    sampled_points = np.insert(sampled_points, 0, 0.)\n",
    "    sampled_points = np.append(sampled_points, 1.)\n",
    "    sampled_points = np.sort(sampled_points)\n",
    "    return sampled_points\n",
    "\n",
    "\n",
    "def generate_consist_tuples(points, tuple_len, max_p):\n",
    "    # given a list of points, create all tuples used for consist condition in tuple_len and each tuple has no more than max_p points\n",
    "    results = []\n",
    "    for r in range(3, max_p + 1):\n",
    "        result = []\n",
    "        for i in range(len(points) - tuple_len+1):#这里可能range（）里面需要加1\n",
    "            this_points = points[i: i+tuple_len]\n",
    "            result = list(set(result + list(itertools.combinations(this_points, r))))\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def calc_consist_loss(model, tuples,\n",
    "                      dtype=torch.float32, device='cpu'):\n",
    "    point_tuples = torch.tensor(tuples, device=device, dtype=dtype)\n",
    "    point_tuples = point_tuples.unsqueeze(-1)\n",
    "    f0s = 0.1 + 0.8 * torch.rand((point_tuples.shape[0], 1), dtype=dtype, device=device)\n",
    "    # one step\n",
    "    deltas = point_tuples[:, -1] - point_tuples[:, 0]\n",
    "    result = f0s + deltas * model(f0s, point_tuples[:, 0], deltas)\n",
    "\n",
    "    # multiple steps\n",
    "    step = point_tuples.shape[1]-1\n",
    "    fs = f0s.clone()\n",
    "    deltas = torch.zeros((step, point_tuples.shape[0], 1), dtype=dtype, device=device)\n",
    "    for i in range(step):\n",
    "        deltas[i] = point_tuples[:, i+1] - point_tuples[:, i]\n",
    "    for i in range(step):\n",
    "        fs = fs + deltas[i] * model(fs, point_tuples[:, i], deltas[i])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    norm_factors = torch.sum(deltas, dim=0)**2\n",
    "    loss = loss_fn(result/norm_factors, fs/norm_factors)\n",
    "    #---------\n",
    "    if(debug==True):print('consist_loss: ',loss.item())\n",
    "    #---------\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_boundary_loss(model, x_segments, repeated_time, tuple_len, boundary_fn,dtype=torch.float32, device='cpu'):\n",
    "    f0s = 0.1 + 0.8 * torch.rand((repeated_time, 1), dtype=dtype, device=device)\n",
    "    ####从0.9改回0.4\n",
    "    f1s = boundary_fn(f0s)\n",
    "    points = x_segments[::tuple_len]\n",
    "    points = torch.from_numpy(points)\n",
    "    points = points.to(dtype=dtype, device=device)\n",
    "    \n",
    "    points = points.unsqueeze(-1).repeat(1, repeated_time)\n",
    "    points = points.unsqueeze(-1)\n",
    "    deltas = points[1:] - points[:-1]\n",
    "    step = len(points)-1\n",
    "    if debug:print('points_of_boundary_loss_calc:',points.squeeze(-1),points.shape)\n",
    "\n",
    "    fs = f0s\n",
    "    for i in range(step):\n",
    "        fs = fs + deltas[i] * model(fs, points[i], deltas[i])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(fs, f1s)\n",
    "    if debug_2:\n",
    "        debug_loss_fun=nn.MSELoss(reduction='none')\n",
    "        debug_loss=debug_loss_fun(fs, f1s)\n",
    "        print('boundary_loss:', debug_loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def iteration(model, p, optimizer, boundary_fn,\n",
    "              tuple_len=8, max_p=6,\n",
    "              dtype=torch.float32, device='cpu'):\n",
    "    #迭代更新函数\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    segments_per_interval = 2**(p)   # 每一个间隔所分割的段数\n",
    "\n",
    "    x_segments = equally_random_points_in_interval(segments_per_interval, num_samples=1)\n",
    "\n",
    "    tuples = generate_consist_tuples(x_segments, tuple_len, max_p)\n",
    "\n",
    "    consist_loss = 0.0\n",
    "\n",
    "    for t in tuples:\n",
    "        temp_consist_loss = calc_consist_loss(model, t, dtype=dtype, device=device)\n",
    "        if debug_2:\n",
    "            print('temp_consist_loss:',temp_consist_loss.item())\n",
    "            print('len of t:',len(t),'  mean loss of t:',temp_consist_loss.item()/len(t))\n",
    "        consist_loss = consist_loss + temp_consist_loss\n",
    "\n",
    "    repeated_time = sum(len(t) for t in tuples)\n",
    "    # #--------------\n",
    "    # if(debug==True):\n",
    "    #     for t in tuples:print('\\n len(t):',len(t),'\\n')\n",
    "    # #--------------\n",
    "    boundary_loss = calc_boundary_loss(model, x_segments, repeated_time, tuple_len, boundary_fn, dtype=dtype, device=device)\n",
    "    if debug_2:print('boundary_loss:',boundary_loss.item())\n",
    "    \n",
    "    boundary_loss_list.append(boundary_loss.item())\n",
    "    consist_loss_list.append(consist_loss.item())\n",
    "    loss = consist_loss  + boundary_loss\n",
    "    # #-----------\n",
    "    # if(debug==True):print('sum_loss:',loss.item())\n",
    "    # #-----------\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train(model, p=7, tuple_len=8, max_p=6,\n",
    "          boundary_fn=ycx.choose_fun,\n",
    "          lr=0.01, num_batches=64, max_epoch=10000,\n",
    "          device='cpu', dtype=torch.float32,\n",
    "          use_scheduler=True, patience=20, threshold=1e-4, cooldown=2):\n",
    "    ####为什么这里的divice='cpu'，而不是device='cuda'呢？\n",
    "    list_epoch_loss_mean=[]\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    #激活训练状态，model.train() 将模型切换到训练模式，以便在训练中启用 Dropout 和 BatchNorm 等特定行为。\n",
    "    #Dropout：在评估过程中，Dropout 层会禁用，即所有神经元都参与计算。\n",
    "    #BatchNorm：在评估过程中，BatchNorm 层会使用在训练过程中计算并存储的全局统计数据，而不是当前批次的数据。\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 **({\"fused\": True} if \"cuda\" in str(device) else {}))#这里的fused=True，是为了使用apex加速\n",
    "\n",
    "    # Use ReduceLROnPlateau as the learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                               patience=ycx.lr_schedule_patience,\n",
    "                                                               threshold=threshold,\n",
    "                                                               cooldown=ycx.lr_schedule_cooldown)\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        lst_loss_epoch = []\n",
    "\n",
    "        for z in range(num_batches):\n",
    "            loss_epoch = iteration(model, p, optimizer=optimizer, boundary_fn=boundary_fn,\n",
    "                                   tuple_len=tuple_len, max_p=max_p, dtype=dtype, device=device)\n",
    "            lst_loss_epoch.append(loss_epoch)\n",
    "\n",
    "        loss_epoch_mean = np.array(lst_loss_epoch).mean()\n",
    "        ####\n",
    "        if(epoch%20==0):\n",
    "            list_epoch_loss_mean.append(loss_epoch_mean)\n",
    "            torch.save(model.state_dict(), f\"test_{p}_{tuple_len}_{max_p}.pth\")\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss = {loss_epoch_mean}, LR = {optimizer.param_groups[0]['lr']}\", flush=True)\n",
    "\n",
    "        if use_scheduler:\n",
    "            scheduler.step(loss_epoch_mean)\n",
    "\n",
    "        if optimizer.param_groups[0][\"lr\"] <= 1.1e-8:\n",
    "            print('terminal epoch: ',epoch)\n",
    "            break\n",
    "    ####\n",
    "    print('list_of_loss_mean_epoch: ',list_epoch_loss_mean)\n",
    "    # Save model ecm to disk\n",
    "    torch.save(model.state_dict(), f\"test_{p}_{tuple_len}_{max_p}.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ti = time.time()\n",
    "    model = ycx.NN()\n",
    "    device = 'cuda'\n",
    "    dtype = torch.float32\n",
    "    \n",
    "    from torch.nn import init\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            init.normal_(param, mean=0, std=0.1)\n",
    "        elif 'bias' in name:\n",
    "            init.constant_(param, val=0)\n",
    "            \n",
    "    train(model, boundary_fn=ycx.choose_fun,max_epoch=ycx.epoch,lr=ycx.lr,tuple_len=8,max_p=6,num_batches=ycx.iteration_num,device=device,dtype=dtype)#修改max_epoch=5\n",
    "    print('---------------------------------')\n",
    "    print('\\n\\nRun time showed here :   ',time.time()-ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundary_loss_list=np.array(boundary_loss_list)\n",
    "consist_loss_list=np.array(consist_loss_list)\n",
    "\n",
    "end=min(3500,len(boundary_loss_list))\n",
    "begin=0\n",
    "\n",
    "plt.plot(boundary_loss_list[begin:end],label='boundary_loss')\n",
    "plt.plot(consist_loss_list[begin:end],label='consist_loss')\n",
    "#plt.ylim(0,0.001)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
